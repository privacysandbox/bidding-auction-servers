#!/usr/bin/env bash
# Copyright 2024 Google LLC

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

print_usage() {
    cat << USAGE
Usage:
  <options>
  --enable_inference                     Enable bidding with inference capabilities
  --gdb                                  Run with GDB
  --use-with-generateBid-file <path>     Use the provided generateBid file for bidding. Path MUST be relative to project root.
  --inference_sidecar_binary_path <path> Path to the inference sidecar binary (default: "/server/bin/inference_sidecar_pytorch_v2_1_1")
  --generate_bid_model_path <path>       Use the provided model for inference. Path MUST be relative to project root (default: "services/inference_sidecar/common/testdata/models/pytorch_generate_bid_model.pt")
  -h, --help                             Print usage information
USAGE
    exit 0
}

source $(dirname "$0")/common

BIDDING_JS_URL="${BIDDING_JS_URL:-}"
EGRESS_SCHEMA_URL="${EGRESS_SCHEMA_URL:-}"
INFERENCE_ARGS="${INFERENCE_ARGS:-}"
INFERENCE_SIDECAR_BINARY_PATH="${INFERENCE_SIDECAR_BINARY_PATH:-/server/bin/inference_sidecar_pytorch_v2_1_1}"
GENERATE_BID_MODEL_PATH="${GENERATE_BID_MODEL_PATH:-services/inference_sidecar/common/testdata/models/pytorch_generate_bid_model.pt}"

declare -i ENABLE_INFERENCE=0
declare -i USE_GDB=0
declare -i CPU_PROF=0
declare GENERATE_BID_FILEPATH=""
declare -i FETCH_MODE=0

while [[ $# -gt 0 ]]; do
  case "$1" in
    --enable_inference)
      ENABLE_INFERENCE=1
      shift
      ;;
    --gdb)
      USE_GDB=1
      shift
      ;;
    --cpu-prof)
      CPU_PROF=1
      shift
      ;;
    --use-with-generateBid-file)
      GENERATE_BID_FILEPATH="$2"
      FETCH_MODE=2
      shift 2
      ;;
    --inference_sidecar_binary_path)
      INFERENCE_SIDECAR_BINARY_PATH="$2"
      shift 2
      ;;
    --generate_bid_model_path)
      GENERATE_BID_MODEL_PATH="$2"
      shift 2
      ;;
    -h | --help) print_usage ;;
    *) print_usage ;;
  esac
done

PROJECT_ROOT=$(git rev-parse --show-toplevel)
export PROJECT_ROOT="${PROJECT_ROOT}"
function get_libcddl_path() {
  declare -a candidates=(
    "bazel-out/k8-opt/bin/external/cddl_lib/libcddl.so"
    "bazel-out/k8-dbg/bin/external/cddl_lib/libcddl.so"
    "bazel-out/k8-opt/bin/production/packaging/aws/bidding_service/libcddl.so"
    "bazel-out/k8-opt/bin/production/packaging/gcp/bidding_service/libcddl.so"
    "bazel-out/k8-opt/dbg/production/packaging/aws/bidding_service/libcddl.so"
    "bazel-out/k8-opt/dbg/production/packaging/gcp/bidding_service/libcddl.so"
  )
  for f in "${candidates[@]}"
  do
    if [[ -f ${PROJECT_ROOT}/$f ]]; then
      echo "${PROJECT_ROOT}/$f"
      break
    fi
  done
}

# Set default buyer code fetch config
BUYER_CODE_FETCH_CONFIG=$(cat << END
{
  "fetchMode": ${FETCH_MODE},
  "biddingJsPath": "/generateBid.js",
  "biddingJsUrl": "${BIDDING_JS_URL}",
  "protectedAppSignalsBiddingJsUrl": "${BIDDING_JS_URL}",
  "biddingWasmHelperUrl": "",
  "protectedAppSignalsBiddingWasmHelperUrl": "",
  "urlFetchPeriodMs": 13000000,
  "urlFetchTimeoutMs": 30000,
  "enableBuyerDebugUrlGeneration": true,
  "prepareDataForAdsRetrievalJsUrl": "${BIDDING_JS_URL}",
  "prepareDataForAdsRetrievalWasmHelperUrl": "",
  "enablePrivateAggregateReporting": false
}
END
)

# Update buyer code fetch config if using JS file
if [[ -n "${GENERATE_BID_FILEPATH}" ]]; then
  BUYER_CODE_FETCH_CONFIG=$(echo "${BUYER_CODE_FETCH_CONFIG}" | "${PROJECT_ROOT}/builders/tools/jq" '.fetchMode = 2')
fi

# Update buyer code fetch config if enabling inference
if [[ ${ENABLE_INFERENCE} -eq 1 ]]; then
  GENERATE_BID_FILEPATH="services/inference_sidecar/common/tools/debug/generateBidRunInference.js"

  INFERENCE_ARGS=$(cat << END
--inference_sidecar_binary_path="${INFERENCE_SIDECAR_BINARY_PATH}" \
--inference_sidecar_runtime_config='{
  "num_interop_threads": 4,
  "num_intraop_threads": 4
}' \
--inference_model_local_paths="/generate_bid_model"
END
)
  BUYER_CODE_FETCH_CONFIG=$(cat << END
{
  "fetchMode": 2,
  "biddingJsPath": "/generateBid.js",
  "urlFetchPeriodMs": 13000000,
  "urlFetchTimeoutMs": 30000,
  "enableBuyerDebugUrlGeneration": true
}
END
)
fi

SERVER_START_CMD=$(cat << END
/server/bin/server \
--https_fetch_skips_tls_verification="${SKIP_TLS_VERIFICATION}" \
--enable_bidding_service_benchmark="true" \
--init_config_client="false" \
--port=${BIDDING_PORT} \
--udf_num_workers=4 \
--js_worker_queue_len=100 \
--test_mode="true" \
--telemetry_config="${TELEMETRY_CONFIG}" \
--roma_timeout_ms="120000" \
--egress_schema_fetch_config='{
      "fetchMode": 0,
      "egressSchemaPath": "",
      "egressSchemaUrl": "${EGRESS_SCHEMA_URL}",
      "temporaryUnlimitedEgressSchemaUrl": "${EGRESS_SCHEMA_URL}",
      "urlFetchPeriodMs": 13000000,
      "urlFetchTimeoutMs": 30000,
    }' \
--buyer_code_fetch_config='${BUYER_CODE_FETCH_CONFIG}' \
--enable_protected_app_signals=${ENABLE_PROTECTED_APP_SIGNALS} \
--enable_otel_based_logging="true" \
--consented_debug_token="test_token" \
--enable_protected_audience=${ENABLE_PROTECTED_AUDIENCE} \
--enable_kanon=${ENABLE_KANON} \
--tee_ad_retrieval_kv_server_addr="localhost:50057" \
--ps_verbosity=${PS_VERBOSITY} \
--max_allowed_size_debug_url_bytes=65536 \
--max_allowed_size_all_debug_urls_kb=3000 \
--bidding_tcmalloc_background_release_rate_bytes_per_second=4096 \
--bidding_tcmalloc_max_total_thread_cache_bytes=10737418240 \
--ad_retrieval_timeout_ms="60000" \
${INFERENCE_ARGS} && exit
END
)

function local_debian_setup {
  cddl_path=$(get_libcddl_path)
  echo "Using libcddl path: ${cddl_path}"

  declare -a extra_docker_run_args=(
    "--volume=${cddl_path}:/usr/lib/libcddl.so"
    "--volume=${PROJECT_ROOT}/bazel-bin/services/bidding_service/server:/server/bin/server"
    "--volume=${PROJECT_ROOT}/services/bidding_service/egress_cddl_spec:/egress_cddl_spec"
    "--volume=${PROJECT_ROOT}/services/inference_sidecar/modules/pytorch_v2_1_1/artifacts/inference_sidecar_pytorch_v2_1_1:/server/bin/inference_sidecar_pytorch_v2_1_1"
    "--volume=${PROJECT_ROOT}/services/inference_sidecar/modules/tensorflow_v2_14_0/artifacts/inference_sidecar_tensorflow_v2_14_0:/server/bin/inference_sidecar_tensorflow_v2_14_0"
    "--volume=${PROJECT_ROOT}/${GENERATE_BID_MODEL_PATH}:/generate_bid_model"
    "--name=bidding"
    "--label=bidding"
  )
  if [[ -n "${GENERATE_BID_FILEPATH}" ]]; then
    extra_docker_run_args+=("--volume=${PROJECT_ROOT}/${GENERATE_BID_FILEPATH}:/generateBid.js")
  fi

  PROF_PORT="${PROF_PORT:-1237}"
  extra_docker_run_args+=(
    "-p ${PROF_PORT}:${PROF_PORT}"
  )
  export EXTRA_DOCKER_RUN_ARGS="${extra_docker_run_args[*]}"
}

if [[ ${USE_GDB} -eq 1 ]]; then
  local_debian_setup
  "${PROJECT_ROOT}/builders/tools/cbuild" --seccomp-unconfined \
  --docker-network host --image build-debian \
  --cmd "apt-get update && apt-get -y install gdb && gdb -ex=r --args ${SERVER_START_CMD}"
elif [[ ${CPU_PROF} -eq 1 ]]; then
  local_debian_setup
  "${PROJECT_ROOT}/builders/tools/cbuild" --seccomp-unconfined \
  --docker-network host --image build-debian --cmd-profiler \
  --cpu-profiler-filename bidding.prof --cpu-profiler-signal 12 \
  --cmd "${SERVER_START_CMD}"
else
  docker_image_uri="${DOCKER_IMAGE_URI:-$(docker load -i dist/debian/bidding_service_image.tar | sed -nr "s/^Loaded image: (.*)$/\1/p")}"
  if [[ -n "${GENERATE_BID_FILEPATH}" ]]; then
    DOCKER_RUN_ARGS+=(
      "--volume=${PROJECT_ROOT}/${GENERATE_BID_FILEPATH}:/generateBid.js"
      "--volume=${PROJECT_ROOT}/${GENERATE_BID_MODEL_PATH}:/generate_bid_model"
    )
  fi
  docker run -it "${DOCKER_RUN_ARGS[@]}" "${docker_image_uri}" -c "${SERVER_START_CMD}"
fi
